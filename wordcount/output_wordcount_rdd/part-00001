('import', 1)
('sparkcontext', 1)
('conf', 1)
('sc', 1)
('支持本地文件（file:///路径）或hdfs文件（hdfs:///路径）', 1)
('转换操作：一系列算子组合', 1)
('line.strip', 1)
('将每行文本按空格分割为单词列表', 1)
('line.split', 1)
('word.strip().lower().strip(\'.,!?;:"()[]\'', 1)
('按单词分组，累加计数（reducebykey是核心聚合算子）', 1)
('按计数降序排序', 1)
('x[1', 1)
('results', 1)
('将分布式计算结果收集到driver端', 1)
('count', 1)
('in', 1)
('results[:100', 1)
('print(f"{word}', 1)
('{count}', 1)
('停止sparkcontext', 1)
('sc.stop', 1)
('__name__', 1)
('==', 1)
('__main__', 1)
('from', 1)
('pyspark', 1)
('sparkconf', 1)
('def', 1)
('配置并初始化sparkcontext', 1)
('sparkconf().setappname("wordcountwithoperators', 1)
('sparkcontext(conf=conf', 1)
('读取文本文件，生成初始rdd', 1)
('sc.textfile("input.txt', 1)
('2', 1)
('word_counts', 1)
('过滤空行', 1)
('flatmap(lambda', 1)
('清洗单词：转为小写并去除标点符号', 1)
('过滤清洗后为空的字符串', 1)
('每个单词映射为(word', 1)
('1)键值对', 1)
('reducebykey(lambda', 1)
('+', 1)
('sortby(lambda', 1)
('x', 1)
('ascending=false', 1)
('3', 1)
('行动操作：获取并输出结果', 1)
('word_counts.collect', 1)
('打印前100个结果', 1)
('for', 1)
('可选：将结果保存到文件', 1)
('word_counts.saveastextfile("output_wordcount_rdd', 1)
('if', 1)
